# AGENTS.md - Tests Directory

This document provides comprehensive guidance for understanding and working with the test suite in the Open LangGraph project. It serves as a companion to the human-readable `README.md` in this directory.

## 1. í…ŒìŠ¤íŠ¸ êµ¬ì¡° ê°œìš” (Test Structure Overview)

Open LangGraphì˜ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œì€ 3ê³„ì¸µ ì•„í‚¤í…ì²˜ë¥¼ ë”°ë¦…ë‹ˆë‹¤:

### Test Pyramid Architecture

```
        /\
       /  \      E2E Tests (Slowest, Most Coverage)
      /____\     End-to-end workflows
     /      \    Integration Tests (Medium Speed)
    /________\   Service + Database
   /          \  Unit Tests (Fastest, Most Granular)
  /__________\   Isolated functions/classes
```

**í•µì‹¬ ì›ì¹™ (Core Principles):**

- **Isolation**: Unit testsëŠ” ì™¸ë¶€ ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
- **Integration**: Integration testsëŠ” ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ ì—°ë™
- **End-to-End**: E2E testsëŠ” ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ë¡œ ê²€ì¦
- **Speed**: í…ŒìŠ¤íŠ¸ëŠ” í”¼ë¼ë¯¸ë“œ í•˜ë‹¨ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ë¹ ë¥´ê²Œ ì‹¤í–‰
- **Coverage**: ê° ë ˆì´ì–´ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ì œê³µ

### LangGraph Integration Testing

Open LangGraphëŠ” LangGraph ìœ„ì— êµ¬ì¶•ë˜ì—ˆìœ¼ë¯€ë¡œ, í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒì„ ê³ ë ¤í•©ë‹ˆë‹¤:

- **State Persistence**: LangGraph checkpointerì™€ storeì˜ ë™ì‘ ê²€ì¦
- **Graph Execution**: Workflow ì‹¤í–‰ ë° ìƒíƒœ ì „ì´ í…ŒìŠ¤íŠ¸
- **Event Streaming**: SSE (Server-Sent Events) ìŠ¤íŠ¸ë¦¬ë° ê²€ì¦
- **Human-in-the-Loop**: Interrupt ë° resume ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

## 2. í…ŒìŠ¤íŠ¸ ìœ í˜• (Test Types)

### Unit Tests (`tests/unit/`)

**ëª©ì  (Purpose)**: ê°œë³„ í•¨ìˆ˜, í´ë˜ìŠ¤, ë©”ì„œë“œë¥¼ ê²©ë¦¬ëœ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸

**íŠ¹ì§• (Characteristics):**
- ì†ë„: âš¡ ë§¤ìš° ë¹ ë¦„ (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
- ì˜ì¡´ì„±: ëª¨ë“  ì™¸ë¶€ ì˜ì¡´ì„±ì€ Mockìœ¼ë¡œ ëŒ€ì²´
- ë²”ìœ„: ë‹¨ì¼ í•¨ìˆ˜/í´ë˜ìŠ¤ì˜ ë¡œì§ ê²€ì¦
- ê²©ë¦¬: ë°ì´í„°ë² ì´ìŠ¤, ë„¤íŠ¸ì›Œí¬, íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ì—†ìŒ

**í•˜ìœ„ ë””ë ‰í† ë¦¬:**
- `test_core/`: í•µì‹¬ ìœ í‹¸ë¦¬í‹° ë° ì¸ì¦ ë¡œì§
  - `test_auth_ctx.py`: ì¸ì¦ ì»¨í…ìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°
  - `test_auth_middleware.py`: ì¸ì¦ ë¯¸ë“¤ì›¨ì–´
  - `test_serializers/`: ì§ë ¬í™” ë¡œì§
  - `test_sse.py`: SSE ì´ë²¤íŠ¸ ìƒì„±
- `test_middleware/`: HTTP ë¯¸ë“¤ì›¨ì–´
  - `test_double_encoded_json.py`: JSON ì¸ì½”ë”© ì²˜ë¦¬
- `test_services/`: ì„œë¹„ìŠ¤ ë ˆì´ì–´ ë¡œì§
  - `test_assistant_service.py`: Assistant ê´€ë¦¬
  - `test_broker.py`: ë©”ì‹œì§€ ë¸Œë¡œì»¤
  - `test_event_converter.py`: ì´ë²¤íŠ¸ ë³€í™˜
  - `test_event_store.py`: ì´ë²¤íŠ¸ ì €ì¥ì†Œ
  - `test_langgraph_service.py`: Graph ë¡œë”© ë° ìºì‹±
- `test_utils/`: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  - `test_assistants_utils.py`: Assistant í—¬í¼
  - `test_sse_utils.py`: SSE ìœ í‹¸ë¦¬í‹°
- `test_observability/`: ê´€ì°°ì„± í†µí•©
  - `test_langfuse_integration.py`: Langfuse íŠ¸ë ˆì´ì‹±

**Example:**
```python
# tests/unit/test_services/test_event_converter.py
from src.agent_server.services.event_converter import EventConverter

class TestEventConverter:
    def setup_method(self):
        self.converter = EventConverter()

    def test_parse_raw_event_tuple_2_elements(self):
        """Test parsing raw event with 2-element tuple"""
        raw_event = ("values", {"key": "value"})
        stream_mode, payload = self.converter._parse_raw_event(raw_event)

        assert stream_mode == "values"
        assert payload == {"key": "value"}
```

### Integration Tests (`tests/integration/`)

**ëª©ì  (Purpose)**: ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ê°€ í•¨ê»˜ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦

**íŠ¹ì§• (Characteristics):**
- ì†ë„: ğŸ¢ ì¤‘ê°„ ì†ë„ (100ms-1s per test)
- ì˜ì¡´ì„±: ì‹¤ì œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤, Mocked ì™¸ë¶€ API
- ë²”ìœ„: ì„œë¹„ìŠ¤ ë ˆì´ì–´ + ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
- ê²©ë¦¬: ê° í…ŒìŠ¤íŠ¸ëŠ” ë…ë¦½ëœ íŠ¸ëœì­ì…˜ì—ì„œ ì‹¤í–‰

**í•˜ìœ„ ë””ë ‰í† ë¦¬:**
- `test_api/`: API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸
  - `test_assistants_crud.py`: Assistant CRUD ì‘ì—…
  - `test_runs_crud.py`: Run CRUD ì‘ì—…
  - `test_store_crud.py`: Store CRUD ì‘ì—…
  - `test_threads_crud.py`: Thread CRUD ì‘ì—…
  - `test_threads_history.py`: Thread íˆìŠ¤í† ë¦¬ ì¡°íšŒ
- `test_services/`: ì„œë¹„ìŠ¤ ë ˆì´ì–´ í†µí•© í…ŒìŠ¤íŠ¸
  - `test_assistant_service_db.py`: Assistant ì„œë¹„ìŠ¤ + DB
  - `test_event_store_integration.py`: ì´ë²¤íŠ¸ ì €ì¥ì†Œ + DB
  - `test_langgraph_service_integration.py`: LangGraph ì„œë¹„ìŠ¤ í†µí•©
  - `test_streaming_hitl.py`: Human-in-the-Loop ìŠ¤íŠ¸ë¦¬ë°

**Example:**
```python
# tests/integration/test_api/test_assistants_crud.py
import pytest
from tests.fixtures.clients import create_test_app, make_client

@pytest.fixture
def client(mock_assistant_service):
    app = create_test_app(include_runs=False, include_threads=False)
    app.dependency_overrides[get_assistant_service] = lambda: mock_assistant_service
    return make_client(app)

class TestCreateAssistant:
    def test_create_assistant_basic(self, client, mock_assistant_service):
        """Test creating a basic assistant"""
        assistant = make_assistant()
        mock_assistant_service.create_assistant.return_value = assistant

        resp = client.post("/assistants", json={
            "name": "Test Assistant",
            "graph_id": "test-graph"
        })

        assert resp.status_code == 200
        assert resp.json()["assistant_id"] == "test-assistant-123"
```

### E2E Tests (`tests/e2e/`)

**ëª©ì  (Purpose)**: ì‹¤ì œ ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°ë¥¼ ì „ì²´ ì‹œìŠ¤í…œì—ì„œ ê²€ì¦

**íŠ¹ì§• (Characteristics):**
- ì†ë„: ğŸŒ ê°€ì¥ ëŠë¦¼ (1s-10s per test)
- ì˜ì¡´ì„±: ì „ì²´ ì‹œìŠ¤í…œ (DB, LangGraph, ëª¨ë“  ì„œë¹„ìŠ¤)
- ë²”ìœ„: ì™„ì „í•œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤
- ê²©ë¦¬: ì‹¤ì œ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ì„¤ì •

**í•˜ìœ„ ë””ë ‰í† ë¦¬:**
- `test_assistants/`: Assistant ê¸°ëŠ¥ E2E
  - `test_assistant_deletion.py`: Assistant ì‚­ì œ ì›Œí¬í”Œë¡œìš°
  - `test_assistant_graph.py`: Graph êµ¬ì¡° ì¡°íšŒ
  - `test_assistant_search.py`: Assistant ê²€ìƒ‰
  - `test_assistant_version.py`: ë²„ì „ ê´€ë¦¬
- `test_runs/`: Run ì‹¤í–‰ E2E
  - `test_runs.py`: ê¸°ë³¸ Run ì‹¤í–‰
  - `test_background_run_join.py`: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ë° Join
  - `test_run_join_output.py`: Join ì¶œë ¥ ê²€ì¦
- `test_threads/`: Thread ê´€ë¦¬ E2E
  - `test_thread_deletion.py`: Thread ì‚­ì œ
  - `test_history_endpoint.py`: íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  - `test_state_endpoint.py`: ìƒíƒœ ì¡°íšŒ
- `test_streaming/`: ìŠ¤íŠ¸ë¦¬ë° E2E
  - `test_chat_streaming.py`: ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë°
  - `test_event_filtering_and_subgraphs.py`: ì´ë²¤íŠ¸ í•„í„°ë§ ë° ì„œë¸Œê·¸ë˜í”„
- `test_store/`: Store E2E
  - `test_store.py`: Store ê¸°ëŠ¥ ì „ì²´ í…ŒìŠ¤íŠ¸
- `test_human_in_loop/`: Human-in-the-Loop E2E
  - `test_human_in_loop.py`: HITL ì›Œí¬í”Œë¡œìš°

**Example:**
```python
# tests/e2e/test_assistants/test_assistant_graph.py
import pytest
from tests.e2e._utils import elog, get_e2e_client

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_get_assistant_graph():
    """Test that we can retrieve the graph structure for an assistant."""
    client = get_e2e_client()

    # Create an assistant
    assistant = await client.assistants.create(
        name="Test Graph Assistant",
        graph_id="agent",
        if_exists="do_nothing"
    )

    try:
        # Get the graph structure
        graph = await client.assistants.get_graph(
            assistant_id=assistant["assistant_id"]
        )

        # Verify graph structure
        assert "nodes" in graph
        assert "edges" in graph
        assert len(graph["nodes"]) > 0

        elog("Graph structure retrieved", {
            "node_count": len(graph["nodes"]),
            "edge_count": len(graph["edges"])
        })
    finally:
        await client.assistants.delete(assistant_id=assistant["assistant_id"])
```

## 3. ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)

```
tests/
â”œâ”€â”€ __init__.py                      # Package initialization
â”œâ”€â”€ conftest.py                      # ê¸€ë¡œë²Œ pytest ì„¤ì • ë° ê³µí†µ í”½ìŠ¤ì²˜
â”œâ”€â”€ README.md                        # Human-readable test documentation
â”œâ”€â”€ AGENTS.md                        # AI agent guidance (this file)
â”‚
â”œâ”€â”€ unit/                            # Unit tests (fast, isolated)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # Unit-specific fixtures
â”‚   â”œâ”€â”€ test_core/                   # Core utilities tests
â”‚   â”‚   â”œâ”€â”€ test_auth_ctx.py         # Authentication context
â”‚   â”‚   â”œâ”€â”€ test_auth_middleware.py  # Auth middleware
â”‚   â”‚   â”œâ”€â”€ test_sse.py              # SSE event generation
â”‚   â”‚   â””â”€â”€ test_serializers/        # Serialization logic
â”‚   â”œâ”€â”€ test_middleware/             # HTTP middleware tests
â”‚   â”‚   â””â”€â”€ test_double_encoded_json.py
â”‚   â”œâ”€â”€ test_services/               # Service layer unit tests
â”‚   â”‚   â”œâ”€â”€ test_assistant_service.py
â”‚   â”‚   â”œâ”€â”€ test_broker.py
â”‚   â”‚   â”œâ”€â”€ test_event_converter.py
â”‚   â”‚   â”œâ”€â”€ test_event_store.py
â”‚   â”‚   â””â”€â”€ test_langgraph_service.py
â”‚   â”œâ”€â”€ test_observability/          # Observability tests
â”‚   â”‚   â””â”€â”€ test_langfuse_integration.py
â”‚   â””â”€â”€ test_utils/                  # Utility function tests
â”‚       â”œâ”€â”€ test_assistants_utils.py
â”‚       â””â”€â”€ test_sse_utils.py
â”‚
â”œâ”€â”€ integration/                     # Integration tests (DB + services)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # Integration-specific fixtures
â”‚   â”œâ”€â”€ test_api/                    # API integration tests
â”‚   â”‚   â”œâ”€â”€ test_assistants_crud.py  # Assistant CRUD operations
â”‚   â”‚   â”œâ”€â”€ test_runs_crud.py        # Run CRUD operations
â”‚   â”‚   â”œâ”€â”€ test_store_crud.py       # Store CRUD operations
â”‚   â”‚   â”œâ”€â”€ test_threads_crud.py     # Thread CRUD operations
â”‚   â”‚   â””â”€â”€ test_threads_history.py  # Thread history queries
â”‚   â””â”€â”€ test_services/               # Service integration tests
â”‚       â”œâ”€â”€ test_assistant_service_db.py
â”‚       â”œâ”€â”€ test_event_store_integration.py
â”‚       â”œâ”€â”€ test_langgraph_service_integration.py
â”‚       â””â”€â”€ test_streaming_hitl.py
â”‚
â”œâ”€â”€ e2e/                             # End-to-end tests (full system)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # E2E-specific fixtures
â”‚   â”œâ”€â”€ _utils.py                    # E2E test utilities
â”‚   â”œâ”€â”€ test_assistants/             # Assistant E2E workflows
â”‚   â”‚   â”œâ”€â”€ test_assistant_deletion.py
â”‚   â”‚   â”œâ”€â”€ test_assistant_graph.py
â”‚   â”‚   â”œâ”€â”€ test_assistant_search.py
â”‚   â”‚   â””â”€â”€ test_assistant_version.py
â”‚   â”œâ”€â”€ test_runs/                   # Run execution E2E
â”‚   â”‚   â”œâ”€â”€ test_runs.py
â”‚   â”‚   â”œâ”€â”€ test_background_run_join.py
â”‚   â”‚   â””â”€â”€ test_run_join_output.py
â”‚   â”œâ”€â”€ test_threads/                # Thread management E2E
â”‚   â”‚   â”œâ”€â”€ test_thread_deletion.py
â”‚   â”‚   â”œâ”€â”€ test_history_endpoint.py
â”‚   â”‚   â””â”€â”€ test_state_endpoint.py
â”‚   â”œâ”€â”€ test_streaming/              # Streaming E2E
â”‚   â”‚   â”œâ”€â”€ test_chat_streaming.py
â”‚   â”‚   â””â”€â”€ test_event_filtering_and_subgraphs.py
â”‚   â”œâ”€â”€ test_store/                  # Store E2E
â”‚   â”‚   â””â”€â”€ test_store.py
â”‚   â””â”€â”€ test_human_in_loop/          # HITL E2E
â”‚       â””â”€â”€ test_human_in_loop.py
â”‚
â””â”€â”€ fixtures/                        # Shared test fixtures and helpers
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ auth.py                      # Authentication fixtures (DummyUser)
    â”œâ”€â”€ clients.py                   # Test client fixtures
    â”œâ”€â”€ database.py                  # Database fixtures
    â”œâ”€â”€ langgraph.py                 # LangGraph mocks (FakeAgent, FakeGraph)
    â”œâ”€â”€ session_fixtures.py          # Session fixtures
    â””â”€â”€ test_helpers.py              # Helper functions (make_assistant, make_thread, make_run)
```

### ê° ë””ë ‰í† ë¦¬ ì—­í•  (Directory Roles)

**`unit/`**: ìµœì†Œí•œì˜ ì˜ì¡´ì„±ìœ¼ë¡œ ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸. ëª¨ë“  ì™¸ë¶€ ì„œë¹„ìŠ¤ëŠ” Mockìœ¼ë¡œ ëŒ€ì²´.

**`integration/`**: ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ ë ˆì´ì–´ì™€ API ë ˆì´ì–´ì˜ í†µí•© ê²€ì¦. LangGraph ê´€ë ¨ ì™¸ë¶€ í˜¸ì¶œì€ ì—¬ì „íˆ Mock.

**`e2e/`**: ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤ì œ ì‚¬ìš©ì ê´€ì ì—ì„œ í…ŒìŠ¤íŠ¸. LangGraph SDK í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ HTTP APIë¥¼ í†µí•œ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ê²€ì¦.

**`fixtures/`**: ëª¨ë“  í…ŒìŠ¤íŠ¸ ë ˆë²¨ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ í—¬í¼, Mock ê°ì²´, í”½ìŠ¤ì²˜ ì œê³µ.

## 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Running Tests)

### Basic Commands

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Run all tests)
uv run pytest

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ë ˆë²¨ ì‹¤í–‰ (Run specific test level)
uv run pytest tests/unit/              # Unit tests only
uv run pytest tests/integration/       # Integration tests only
uv run pytest tests/e2e/              # E2E tests only

# íŠ¹ì • íŒŒì¼ ì‹¤í–‰ (Run specific file)
uv run pytest tests/unit/test_services/test_event_converter.py

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ì‹¤í–‰ (Run specific test class)
uv run pytest tests/unit/test_services/test_event_converter.py::TestEventConverter

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ ì‹¤í–‰ (Run specific test method)
uv run pytest tests/unit/test_services/test_event_converter.py::TestEventConverter::test_parse_raw_event_tuple_2_elements
```

### Advanced Options

```bash
# Verbose output (ìì„¸í•œ ì¶œë ¥)
uv run pytest -v

# Very verbose output (ë§¤ìš° ìì„¸í•œ ì¶œë ¥)
uv run pytest -vv

# Show local variables on failure (ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ë³€ìˆ˜ í‘œì‹œ)
uv run pytest -l

# Stop on first failure (ì²« ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨)
uv run pytest -x

# Run only failed tests from last run (ë§ˆì§€ë§‰ ì‹¤í–‰ì—ì„œ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë§Œ)
uv run pytest --lf

# Run failed tests first, then others (ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¨¼ì €, ê·¸ ë‹¤ìŒ ë‚˜ë¨¸ì§€)
uv run pytest --ff

# Async mode (ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›)
uv run pytest -v --asyncio-mode=auto
```

### Test Markers

```bash
# pytest ë§ˆì»¤ë¥¼ ì‚¬ìš©í•œ í•„í„°ë§ (Filter by pytest markers)
uv run pytest -m unit              # @pytest.mark.unit í…ŒìŠ¤íŠ¸ë§Œ
uv run pytest -m integration       # @pytest.mark.integration í…ŒìŠ¤íŠ¸ë§Œ
uv run pytest -m e2e              # @pytest.mark.e2e í…ŒìŠ¤íŠ¸ë§Œ
uv run pytest -m "not slow"       # ëŠë¦° í…ŒìŠ¤íŠ¸ ì œì™¸
uv run pytest -m "unit or integration"  # Unit ë˜ëŠ” Integration í…ŒìŠ¤íŠ¸
```

### Coverage Reports

```bash
# ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ì¸¡ì • (Measure code coverage)
uv run pytest --cov=src/agent_server

# HTML ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ìƒì„± (Generate HTML coverage report)
uv run pytest --cov=src/agent_server --cov-report=html

# í„°ë¯¸ë„ì— ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ì¶œë ¥ (Print coverage report to terminal)
uv run pytest --cov=src/agent_server --cov-report=term-missing

# ì»¤ë²„ë¦¬ì§€ ìµœì†Œ ì„ê³„ê°’ ì„¤ì • (Set minimum coverage threshold)
uv run pytest --cov=src/agent_server --cov-fail-under=80
```

### Parallel Execution

```bash
# pytest-xdistë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰ (Run tests in parallel using pytest-xdist)
# Note: Install first with `uv add --dev pytest-xdist`
uv run pytest -n auto              # Auto-detect CPU count
uv run pytest -n 4                 # Run on 4 cores
```

### Output Control

```bash
# Capture control (ì¶œë ¥ ìº¡ì²˜ ì œì–´)
uv run pytest -s                   # Show print statements (no capture)
uv run pytest --capture=no         # Same as -s
uv run pytest --tb=short           # Shorter traceback format
uv run pytest --tb=line            # One line per failure
uv run pytest --tb=no              # No traceback
```

### E2E Test Execution

E2E í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ ì„œë²„ê°€ í•„ìš”í•©ë‹ˆë‹¤:

```bash
# 1. Start the database (ë°ì´í„°ë² ì´ìŠ¤ ì‹œì‘)
docker compose up postgres -d

# 2. Run migrations (ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰)
python3 scripts/migrate.py upgrade

# 3. Start the server (ì„œë²„ ì‹œì‘)
uv run uvicorn src.agent_server.main:app --reload

# 4. In another terminal, run E2E tests (ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
uv run pytest tests/e2e/

# Or use Docker Compose for full setup (ë˜ëŠ” Docker Composeë¡œ ì „ì²´ ì„¤ì •)
docker compose up open-langgraph -d
uv run pytest tests/e2e/
```

**Environment Variables for E2E:**

```bash
# Set custom server URL (ì»¤ìŠ¤í…€ ì„œë²„ URL ì„¤ì •)
SERVER_URL=http://localhost:8000 uv run pytest tests/e2e/

# Use different auth type (ë‹¤ë¥¸ ì¸ì¦ íƒ€ì… ì‚¬ìš©)
AUTH_TYPE=noop uv run pytest tests/e2e/
```

### Makefile Shortcuts

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ `Makefile`ì€ í¸ë¦¬í•œ ë‹¨ì¶• ëª…ë ¹ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```bash
# Run all tests (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
make test

# Run with coverage (ì»¤ë²„ë¦¬ì§€ ì¸¡ì •)
make test-cov

# Run specific test types
make test-unit          # Unit tests only
make test-integration   # Integration tests only
make test-e2e          # E2E tests only
```

## 5. í”½ìŠ¤ì²˜ ë° í—¬í¼ (Fixtures and Helpers)

### Global Fixtures (`tests/conftest.py`)

ì „ì—­ í”½ìŠ¤ì²˜ëŠ” ëª¨ë“  í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

**Available Global Fixtures:**

```python
# User fixtures
dummy_user              # DummyUser instance
test_user_identity      # String: "test-user"

# Session fixtures
basic_session           # BasicSession mock
basic_client            # Test client with basic session
threads_client          # Test client for thread operations
runs_client             # Test client for run operations

# Service mocks
mock_assistant_service  # AsyncMock for assistant service
mock_store              # AsyncMock for store
```

**Usage Example:**

```python
def test_example(dummy_user, basic_client):
    """Test using global fixtures"""
    assert dummy_user.user_id == "test-user"
    response = basic_client.get("/health")
    assert response.status_code == 200
```

### Fixture Modules (`tests/fixtures/`)

#### `auth.py` - Authentication Fixtures

```python
from tests.fixtures.auth import DummyUser

# DummyUser provides a mock user for testing
user = DummyUser()
print(user.user_id)  # "test-user"
print(user.metadata)  # {"role": "user"}
```

#### `clients.py` - Test Client Fixtures

```python
from tests.fixtures.clients import (
    create_test_app,
    make_client,
    install_dummy_user_middleware
)

# Create a FastAPI test app
app = create_test_app(
    include_runs=True,
    include_threads=True
)

# Create a test client
client = make_client(app)

# Install dummy user middleware for auth
install_dummy_user_middleware(app)
```

#### `database.py` - Database Fixtures

```python
from tests.fixtures.database import (
    DummySessionBase,
    override_get_session_dep
)

# Mock database session
session = DummySessionBase()

# Override FastAPI dependency
override_get_session_dep(app, DummySessionBase)
```

#### `langgraph.py` - LangGraph Mocks

```python
from tests.fixtures.langgraph import (
    FakeAgent,
    FakeGraph,
    FakeSnapshot,
    make_snapshot,
    patch_langgraph_service
)

# Create fake snapshot
snapshot = make_snapshot(
    values={"state": "data"},
    cfg={"configurable": {"thread_id": "123"}},
    next_nodes=["node_1"]
)

# Create fake agent with snapshots
agent = FakeAgent(snapshots=[snapshot])

# Create fake graph with events
graph = FakeGraph(events=[
    ("values", {"key": "value"}),
    ("updates", {"data": "test"})
])

# Patch LangGraph service for testing
with patch_langgraph_service(agent=agent):
    # Your test code here
    pass
```

#### `test_helpers.py` - Model Factories

```python
from tests.fixtures.test_helpers import (
    make_assistant,
    make_thread,
    make_run,
    DummyRun,
    DummyThread,
    DummyStoreItem
)

# Create test models
assistant = make_assistant(
    assistant_id="asst-123",
    name="Test Assistant",
    graph_id="my-graph",
    user_id="user-123"
)

thread = make_thread(
    thread_id="thread-123",
    status="idle",
    user_id="user-123"
)

run = make_run(
    run_id="run-123",
    thread_id="thread-123",
    assistant_id="asst-123",
    status="running",
    user_id="user-123"
)

# Or use dummy classes
dummy_run = DummyRun(run_id="run-456")
dummy_thread = DummyThread(thread_id="thread-456")
```

#### `session_fixtures.py` - Session Fixtures

```python
from tests.fixtures.session_fixtures import (
    BasicSession,
    ThreadSession,
    RunSession,
    override_session_dependency
)

# Different session types for different scenarios
basic_session = BasicSession()
thread_session = ThreadSession()
run_session = RunSession()

# Override session dependency in app
override_session_dependency(app, ThreadSession)
```

### E2E Utilities (`tests/e2e/_utils.py`)

```python
from tests.e2e._utils import elog, get_e2e_client

# Get LangGraph SDK client for E2E tests
client = get_e2e_client()  # Uses SERVER_URL env var

# Pretty-print logs for E2E visibility
elog("Test Step", {"key": "value", "status": "success"})
# Output:
# === Test Step ===
# {
#   "key": "value",
#   "status": "success"
# }
```

### Custom Fixtures by Test Level

ê° í…ŒìŠ¤íŠ¸ ë ˆë²¨ì€ ìì²´ `conftest.py`ì—ì„œ íŠ¹í™”ëœ í”½ìŠ¤ì²˜ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **`tests/unit/conftest.py`**: Unit testì— íŠ¹í™”ëœ í”½ìŠ¤ì²˜
- **`tests/integration/conftest.py`**: Integration testì— íŠ¹í™”ëœ í”½ìŠ¤ì²˜
- **`tests/e2e/conftest.py`**: E2E testì— íŠ¹í™”ëœ í”½ìŠ¤ì²˜

## 6. í…ŒìŠ¤íŠ¸ ì‘ì„± ê°€ì´ë“œ (Test Writing Guide)

### Unit Test ì‘ì„± íŒ¨í„´

**Structure:**

```python
"""Module docstring describing what's being tested"""

import pytest
from unittest.mock import Mock, AsyncMock, patch

from src.agent_server.module import ClassToTest


class TestClassName:
    """Test class for ClassName"""

    def setup_method(self):
        """Setup runs before each test method"""
        self.instance = ClassToTest()

    def teardown_method(self):
        """Cleanup runs after each test method"""
        pass

    def test_method_success_case(self):
        """Test method behavior in success case"""
        # Arrange
        input_data = {"key": "value"}

        # Act
        result = self.instance.method(input_data)

        # Assert
        assert result == expected_value

    def test_method_error_case(self):
        """Test method behavior when error occurs"""
        # Arrange
        invalid_input = None

        # Act & Assert
        with pytest.raises(ValueError):
            self.instance.method(invalid_input)
```

**Best Practices:**

1. **AAA Pattern**: Arrange, Act, Assert
2. **Descriptive Names**: `test_<method>_<scenario>_<expected>`
3. **One Concept**: í•˜ë‚˜ì˜ í…ŒìŠ¤íŠ¸ëŠ” í•˜ë‚˜ì˜ ê°œë…ë§Œ ê²€ì¦
4. **Mock External Dependencies**: ì™¸ë¶€ ì˜ì¡´ì„±ì€ í•­ìƒ Mock
5. **Use Fixtures**: ê³µí†µ ì„¤ì •ì€ í”½ìŠ¤ì²˜ë¡œ ì¶”ì¶œ

**Example - Testing with Mocks:**

```python
from unittest.mock import AsyncMock, patch
import pytest

class TestAssistantService:
    @pytest.fixture
    def mock_session(self):
        """Mock database session"""
        session = AsyncMock()
        session.execute.return_value.scalars.return_value.first.return_value = None
        return session

    @pytest.mark.asyncio
    async def test_create_assistant_success(self, mock_session):
        """Test successful assistant creation"""
        # Arrange
        service = AssistantService(session=mock_session)
        data = {"name": "Test", "graph_id": "my-graph"}

        # Act
        result = await service.create_assistant(data, user_id="user-123")

        # Assert
        assert result.name == "Test"
        assert result.graph_id == "my-graph"
        mock_session.add.assert_called_once()
        mock_session.commit.assert_called_once()
```

### Integration Test ì‘ì„± íŒ¨í„´

**Structure:**

```python
import pytest
from tests.fixtures.database import get_test_db_session
from src.agent_server.services import AssistantService


@pytest.mark.integration
class TestAssistantServiceIntegration:
    """Integration tests for AssistantService with real database"""

    @pytest.fixture
    async def db_session(self):
        """Get real test database session"""
        async with get_test_db_session() as session:
            yield session
            # Cleanup happens after yield

    @pytest.mark.asyncio
    async def test_crud_operations(self, db_session):
        """Test complete CRUD workflow with database"""
        service = AssistantService(session=db_session)

        # Create
        assistant = await service.create_assistant(
            {"name": "Test", "graph_id": "graph"},
            user_id="user-123"
        )
        assert assistant.assistant_id is not None

        # Read
        retrieved = await service.get_assistant(assistant.assistant_id)
        assert retrieved.name == "Test"

        # Update
        updated = await service.update_assistant(
            assistant.assistant_id,
            {"name": "Updated"}
        )
        assert updated.name == "Updated"

        # Delete
        await service.delete_assistant(assistant.assistant_id)
        deleted = await service.get_assistant(assistant.assistant_id)
        assert deleted is None
```

**Best Practices:**

1. **Real Database**: ì‹¤ì œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
2. **Transaction Isolation**: ê° í…ŒìŠ¤íŠ¸ëŠ” ë…ë¦½ëœ íŠ¸ëœì­ì…˜
3. **Cleanup**: í…ŒìŠ¤íŠ¸ í›„ ë°ì´í„° ì •ë¦¬
4. **Test Data**: ì˜ë¯¸ ìˆëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
5. **Async/Await**: ë¹„ë™ê¸° ì‘ì—… ì ì ˆíˆ ì²˜ë¦¬

### E2E Test ì‘ì„± íŒ¨í„´

**Structure:**

```python
import pytest
from tests.e2e._utils import elog, get_e2e_client


@pytest.mark.e2e
@pytest.mark.asyncio
async def test_complete_workflow():
    """Test complete user workflow from start to finish"""
    client = get_e2e_client()

    # Step 1: Create assistant
    assistant = await client.assistants.create(
        name="E2E Test Assistant",
        graph_id="agent"
    )
    elog("Assistant created", assistant)

    try:
        # Step 2: Create thread
        thread = await client.threads.create(
            metadata={"test": "e2e"}
        )
        elog("Thread created", thread)

        # Step 3: Create run
        run = await client.runs.create(
            thread_id=thread["thread_id"],
            assistant_id=assistant["assistant_id"],
            input={"message": "Hello"}
        )
        elog("Run created", run)

        # Step 4: Wait for completion
        await client.runs.join(
            thread_id=thread["thread_id"],
            run_id=run["run_id"]
        )

        # Step 5: Verify results
        final_run = await client.runs.get(
            thread_id=thread["thread_id"],
            run_id=run["run_id"]
        )
        assert final_run["status"] == "success"
        elog("Run completed successfully", final_run)

    finally:
        # Cleanup
        await client.assistants.delete(
            assistant_id=assistant["assistant_id"]
        )
```

**Best Practices:**

1. **Full System**: ì „ì²´ ì‹œìŠ¤í…œ ì‚¬ìš© (DB, LangGraph, API)
2. **Real Workflows**: ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ì¬í˜„
3. **Cleanup**: finally ë¸”ë¡ì—ì„œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
4. **Logging**: `elog()`ë¡œ ê° ë‹¨ê³„ ë¡œê¹…
5. **Assertions**: ì¤‘ìš”í•œ ìƒíƒœ ì „ì´ ê²€ì¦

### Parametrized Tests

ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ë¡œì§ì„ ì—¬ëŸ¬ ì…ë ¥ê°’ìœ¼ë¡œ ì‹¤í–‰:

```python
import pytest

@pytest.mark.parametrize("input,expected", [
    ("hello", "HELLO"),
    ("world", "WORLD"),
    ("Test", "TEST"),
])
def test_uppercase(input, expected):
    """Test uppercase conversion with multiple inputs"""
    assert input.upper() == expected


@pytest.mark.parametrize("status", ["idle", "running", "completed", "failed"])
@pytest.mark.asyncio
async def test_thread_status_transitions(status):
    """Test thread behavior for different statuses"""
    thread = make_thread(status=status)
    assert thread.status == status
```

### Async Tests

ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ëŠ” `@pytest.mark.asyncio` ì‚¬ìš©:

```python
import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_async_endpoint():
    """Test async API endpoint"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/health")
        assert response.status_code == 200


@pytest.mark.asyncio
async def test_async_service_method():
    """Test async service method"""
    service = MyAsyncService()
    result = await service.async_method()
    assert result is not None
```

### Testing Exceptions

ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:

```python
import pytest
from src.agent_server.exceptions import AssistantNotFoundError

def test_raises_exception():
    """Test that exception is raised"""
    with pytest.raises(ValueError):
        raise ValueError("Test error")


def test_raises_with_message():
    """Test exception with specific message"""
    with pytest.raises(ValueError, match="Test error"):
        raise ValueError("Test error")


@pytest.mark.asyncio
async def test_async_raises():
    """Test async exception"""
    async def failing_function():
        raise AssistantNotFoundError("assistant-123")

    with pytest.raises(AssistantNotFoundError) as exc_info:
        await failing_function()

    assert "assistant-123" in str(exc_info.value)
```

### Testing with Context Managers

ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸:

```python
from unittest.mock import patch

def test_with_context_manager():
    """Test using context manager"""
    with patch('module.function') as mock_func:
        mock_func.return_value = "mocked"
        result = function_that_calls_function()
        assert result == "mocked"
        mock_func.assert_called_once()
```

### Testing Streaming

SSE ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸:

```python
@pytest.mark.asyncio
async def test_streaming_events():
    """Test SSE streaming"""
    client = get_e2e_client()

    # Create run
    run = await client.runs.create(...)

    # Stream events
    events = []
    async for chunk in client.runs.stream(
        thread_id=run["thread_id"],
        run_id=run["run_id"]
    ):
        events.append(chunk)

    # Verify events
    assert len(events) > 0
    assert events[0]["event"] == "metadata"
    assert events[-1]["event"] == "end"
```

### Test Organization Checklist

ìƒˆ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•  ë•Œ:

- [ ] ì ì ˆí•œ í…ŒìŠ¤íŠ¸ ë ˆë²¨ ì„ íƒ (unit/integration/e2e)
- [ ] ëª…í™•í•˜ê³  ì„¤ëª…ì ì¸ í…ŒìŠ¤íŠ¸ ì´ë¦„
- [ ] Docstringìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ëª©ì  ì„¤ëª…
- [ ] ì ì ˆí•œ ë§ˆì»¤ ì¶”ê°€ (`@pytest.mark.unit`, etc.)
- [ ] AAA íŒ¨í„´ ë”°ë¥´ê¸° (Arrange, Act, Assert)
- [ ] ì™¸ë¶€ ì˜ì¡´ì„± ì ì ˆíˆ Mock
- [ ] í…ŒìŠ¤íŠ¸ í›„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (cleanup)
- [ ] Edge cases ë° error cases í…ŒìŠ¤íŠ¸
- [ ] ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ì— `@pytest.mark.asyncio` ì‚¬ìš©

## 7. CI/CD Integration

### GitHub Actions Workflow

í…ŒìŠ¤íŠ¸ëŠ” CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ë‹¤ìŒ ìˆœì„œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤:

```yaml
# .github/workflows/test.yml
stages:
  - lint           # Code quality checks
  - unit           # Fast unit tests
  - integration    # Integration tests (if unit passes)
  - e2e           # E2E tests (if integration passes)
```

**Optimization Strategy:**

1. **Fast Feedback**: Unit testsê°€ ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ ë¹ ë¥¸ í”¼ë“œë°± ì œê³µ
2. **Fail Fast**: ì´ì „ ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë‹¨ê³„ ê±´ë„ˆëœ€
3. **Resource Efficiency**: ëŠë¦° í…ŒìŠ¤íŠ¸ëŠ” í•„ìš”í•  ë•Œë§Œ ì‹¤í–‰
4. **Parallel Execution**: ê°€ëŠ¥í•œ ê²½ìš° í…ŒìŠ¤íŠ¸ ë³‘ë ¬ ì‹¤í–‰

### Pre-commit Hooks

ë¡œì»¬ ê°œë°œ ì‹œ ìë™ ê²€ì¦:

```bash
# Install pre-commit hooks
make dev-install

# Hooks will run on git commit:
# - ruff format (code formatting)
# - ruff check (linting)
# - mypy (type checking)
# - pytest tests/unit/ (fast unit tests)
```

## 8. Troubleshooting

### Common Issues

**Import Errors:**

```bash
# Problem: ModuleNotFoundError
# Solution: Run pytest from project root
cd /Users/jhj/Desktop/personal/opensource-langgraph-platform
uv run pytest tests/
```

**Database Connection Errors:**

```bash
# Problem: Cannot connect to database
# Solution: Ensure Docker is running
docker compose up postgres -d

# Verify database is accessible
docker compose ps
```

**Async Test Warnings:**

```bash
# Problem: RuntimeWarning about async generators
# Solution: Use --asyncio-mode=auto
uv run pytest --asyncio-mode=auto
```

**Fixture Not Found:**

```python
# Problem: fixture 'xxx' not found
# Solution: Check conftest.py imports and fixture scope

# Make sure fixture is defined in accessible conftest.py
# or imported in the test file
from tests.fixtures.auth import DummyUser
```

**E2E Tests Timeout:**

```bash
# Problem: E2E tests hang or timeout
# Solution: Increase timeout or check server status

# Check if server is running
curl http://localhost:8000/health

# Set custom timeout in pytest.ini
[tool.pytest.ini_options]
asyncio_default_fixture_loop_scope = "function"
timeout = 300
```

### Debugging Tips

**Print Debugging:**

```bash
# Show print statements during test execution
uv run pytest -s

# Show local variables on failure
uv run pytest -l
```

**Verbose Output:**

```bash
# Show detailed test output
uv run pytest -vv

# Show full diff for assertions
uv run pytest -vv --tb=long
```

**Run Specific Test:**

```bash
# When a test fails, run only that test
uv run pytest tests/unit/test_services/test_event_converter.py::TestEventConverter::test_parse_raw_event_tuple_2_elements -vv
```

**Debug with PDB:**

```python
def test_debug_example():
    """Test with debugger"""
    import pdb; pdb.set_trace()  # Breakpoint
    result = function_to_debug()
    assert result == expected
```

```bash
# Run with PDB
uv run pytest --pdb  # Drop into debugger on failure
```

## 9. Best Practices Summary

### Testing Principles

1. **Fast Feedback Loop**: Unit testsê°€ ëŒ€ë¶€ë¶„ì˜ ë¡œì§ ì»¤ë²„
2. **Test Pyramid**: ë§ì€ unit tests, ì ë‹¹í•œ integration tests, ì ì€ E2E tests
3. **DRY (Don't Repeat Yourself)**: ê³µí†µ ë¡œì§ì€ í”½ìŠ¤ì²˜ë¡œ ì¶”ì¶œ
4. **Isolation**: ê° í…ŒìŠ¤íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
5. **Clarity**: í…ŒìŠ¤íŠ¸ ì´ë¦„ê³¼ êµ¬ì¡°ë¡œ ì˜ë„ ëª…í™•íˆ ì „ë‹¬

### Code Quality

1. **Descriptive Names**: í…ŒìŠ¤íŠ¸ ì´ë¦„ì´ ë¬¸ì„œ ì—­í• 
2. **Comments**: ë³µì¡í•œ ë¡œì§ì— ì£¼ì„ ì¶”ê°€
3. **Assertions**: ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ assertion
4. **Error Messages**: ì‹¤íŒ¨ ì‹œ ìœ ìš©í•œ ì—ëŸ¬ ë©”ì‹œì§€
5. **Coverage**: ì¤‘ìš”í•œ ì½”ë“œ ê²½ë¡œ ëª¨ë‘ í…ŒìŠ¤íŠ¸

### Maintenance

1. **Keep Tests Updated**: ì½”ë“œ ë³€ê²½ ì‹œ í…ŒìŠ¤íŠ¸ë„ ì—…ë°ì´íŠ¸
2. **Refactor Tests**: í…ŒìŠ¤íŠ¸ ì½”ë“œë„ ë¦¬íŒ©í† ë§ í•„ìš”
3. **Remove Obsolete Tests**: ë¶ˆí•„ìš”í•œ í…ŒìŠ¤íŠ¸ ì œê±°
4. **Monitor Performance**: ëŠë ¤ì§€ëŠ” í…ŒìŠ¤íŠ¸ ìµœì í™”
5. **Document Changes**: í…ŒìŠ¤íŠ¸ êµ¬ì¡° ë³€ê²½ ì‹œ ë¬¸ì„œ ì—…ë°ì´íŠ¸

## 10. Additional Resources

### Documentation

- **README.md**: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í…ŒìŠ¤íŠ¸ ê°œìš”
- **AGENTS.md** (this file): AI agentë¥¼ ìœ„í•œ ìƒì„¸ ê°€ì´ë“œ
- **CLAUDE.md** (project root): í”„ë¡œì íŠ¸ ì „ì²´ ê°€ì´ë“œ

### External References

- [pytest documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [LangGraph Testing](https://langchain-ai.github.io/langgraph/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)

### Internal Tools

- **Makefile**: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë‹¨ì¶• ëª…ë ¹ì–´
- **pyproject.toml**: pytest ì„¤ì • ë° dependencies
- **.github/workflows/**: CI/CD íŒŒì´í”„ë¼ì¸ ì •ì˜

---

**Last Updated**: 2025-10-27
**Maintained by**: Open LangGraph Development Team
**For Questions**: Open an issue or PR in the repository
